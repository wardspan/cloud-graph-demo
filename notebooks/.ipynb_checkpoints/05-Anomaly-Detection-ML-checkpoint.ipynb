{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Machine Learning for Security Anomaly Detection\n",
    "\n",
    "> **Learning Objective:** Apply machine learning to security graphs for automated threat detection with clear explanations\n",
    "\n",
    "## üéì What You'll Learn\n",
    "- **ML Fundamentals for Security:** Why machine learning works for threat detection\n",
    "- **Graph-Based Features:** How to extract meaningful security features from graphs\n",
    "- **Anomaly Detection Models:** Practical algorithms with step-by-step explanations\n",
    "- **Model Interpretation:** Understanding what your models are actually detecting\n",
    "- **Real-World Application:** Implementing automated security monitoring\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Why Machine Learning for Security?\n",
    "\n",
    "### The Security Challenge\n",
    "**Traditional Rule-Based Detection:**\n",
    "- Fixed rules that attackers can learn to evade\n",
    "- High false positive rates\n",
    "- Cannot adapt to new attack patterns\n",
    "- Requires constant manual updates\n",
    "\n",
    "**Machine Learning Approach:**\n",
    "- Learns normal behavior patterns automatically\n",
    "- Adapts to new and evolving threats\n",
    "- Identifies subtle anomalies humans might miss\n",
    "- Scales to analyze massive datasets\n",
    "\n",
    "### Educational Philosophy\n",
    "In this notebook, we'll explain **why** each algorithm works, **how** to interpret results, and **when** to use different approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Educational ML Setup with Detailed Explanations\n",
    "import sys\n",
    "!{sys.executable} -m pip install neo4j scikit-learn matplotlib seaborn plotly pandas numpy networkx\n",
    "\n",
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Graph and Database\n",
    "from neo4j import GraphDatabase\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ü§ñ Machine Learning Security Lab Initialized!\")\n",
    "print(\"üìö Ready for explainable AI-driven threat detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Building Our Security ML Pipeline\n",
    "\n",
    "Let's create a comprehensive framework for security-focused machine learning with full explanations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SecurityMLEducation:\n",
    "    \"\"\"\n",
    "    Educational framework for machine learning in cybersecurity\n",
    "    \n",
    "    This class provides:\n",
    "    1. Clear explanations of why we use each technique\n",
    "    2. Step-by-step algorithm implementations\n",
    "    3. Practical interpretation of results\n",
    "    4. Real-world security applications\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, uri=\"bolt://neo4j:7687\", user=\"neo4j\", password=\"cloudsecurity\"):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "        self.security_features = pd.DataFrame()\n",
    "        self.models = {}\n",
    "        self.explanations = {}\n",
    "        print(\"üî¨ Security ML Education Framework Ready!\")\n",
    "    \n",
    "    def explain_concept(self, concept, explanation):\n",
    "        \"\"\"\n",
    "        Educational function to explain ML concepts clearly\n",
    "        \"\"\"\n",
    "        print(f\"\\nüéì CONCEPT: {concept}\")\n",
    "        print(\"=\"*50)\n",
    "        print(explanation)\n",
    "        print(\"=\"*50)\n",
    "    \n",
    "    def extract_security_features(self):\n",
    "        \"\"\"\n",
    "        Extract meaningful security features from our graph database\n",
    "        \n",
    "        EDUCATIONAL NOTE:\n",
    "        Features are the \"inputs\" to our ML models. Good features are:\n",
    "        - Relevant to security (access patterns, privilege levels)\n",
    "        - Measurable from our data (node counts, path lengths)\n",
    "        - Discriminative (help distinguish normal from anomalous)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.explain_concept(\n",
    "            \"Feature Engineering for Security\",\n",
    "            \"\"\"\n",
    "Why Feature Engineering Matters:\n",
    "Machine learning models don't understand \"security\" directly.\n",
    "We need to translate security concepts into numbers:\n",
    "\n",
    "‚Ä¢ Access Patterns ‚Üí Statistical measures\n",
    "‚Ä¢ Privilege Levels ‚Üí Numerical rankings\n",
    "‚Ä¢ Network Relationships ‚Üí Graph metrics\n",
    "‚Ä¢ Behavioral Patterns ‚Üí Time-series features\n",
    "\n",
    "Think of it like teaching a computer to \"see\" security risks.\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        # Query to extract user behavior features\n",
    "        feature_query = \"\"\"\n",
    "        MATCH (user:User)\n",
    "        OPTIONAL MATCH (user)-[access_rel]->(target)\n",
    "        WITH user,\n",
    "             count(access_rel) as total_access_count,\n",
    "             count(DISTINCT target) as unique_targets_accessed,\n",
    "             collect(DISTINCT labels(target)[0]) as target_types,\n",
    "             collect(DISTINCT type(access_rel)) as access_methods\n",
    "        \n",
    "        OPTIONAL MATCH (user)-[*1..3]->(sensitive)\n",
    "        WHERE sensitive.contains_pii = true OR sensitive.type = 'S3Bucket'\n",
    "        WITH user, total_access_count, unique_targets_accessed, \n",
    "             target_types, access_methods,\n",
    "             count(DISTINCT sensitive) as sensitive_data_reachable\n",
    "        \n",
    "        OPTIONAL MATCH (user)-[:ASSUMES_ROLE]->(role:Role)\n",
    "        WITH user, total_access_count, unique_targets_accessed,\n",
    "             target_types, access_methods, sensitive_data_reachable,\n",
    "             count(role) as roles_assumed\n",
    "        \n",
    "        RETURN \n",
    "            user.name as user_name,\n",
    "            user.access_level as access_level,\n",
    "            total_access_count,\n",
    "            unique_targets_accessed,\n",
    "            size(target_types) as target_diversity,\n",
    "            size(access_methods) as access_method_diversity,\n",
    "            sensitive_data_reachable,\n",
    "            roles_assumed,\n",
    "            CASE user.access_level\n",
    "                WHEN 'administrator' THEN 5\n",
    "                WHEN 'developer' THEN 3\n",
    "                ELSE 1\n",
    "            END as privilege_level\n",
    "        \"\"\"\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(feature_query)\n",
    "            features_data = [dict(record) for record in result]\n",
    "        \n",
    "        self.security_features = pd.DataFrame(features_data)\n",
    "        \n",
    "        print(f\"\\nüìä Extracted {len(self.security_features)} user profiles with security features:\")\n",
    "        print(f\"Features: {list(self.security_features.columns)}\")\n",
    "        \n",
    "        # Display sample features with explanations\n",
    "        print(\"\\nüîç Sample Security Features:\")\n",
    "        display_cols = ['user_name', 'access_level', 'total_access_count', \n",
    "                       'sensitive_data_reachable', 'privilege_level']\n",
    "        print(self.security_features[display_cols].head())\n",
    "        \n",
    "        # Feature explanations\n",
    "        feature_explanations = {\n",
    "            'total_access_count': 'How many things this user can access (higher = more activity)',\n",
    "            'unique_targets_accessed': 'Number of different resources accessed (diversity)',\n",
    "            'target_diversity': 'Types of resources accessed (databases, files, etc.)',\n",
    "            'access_method_diversity': 'Different ways user gains access (roles, direct, etc.)',\n",
    "            'sensitive_data_reachable': 'How much sensitive data user can potentially access',\n",
    "            'roles_assumed': 'Number of privilege escalation paths available',\n",
    "            'privilege_level': 'Numerical representation of user permissions'\n",
    "        }\n",
    "        \n",
    "        print(\"\\nüí° What These Features Mean for Security:\")\n",
    "        for feature, explanation in feature_explanations.items():\n",
    "            if feature in self.security_features.columns:\n",
    "                print(f\"‚Ä¢ {feature}: {explanation}\")\n",
    "        \n",
    "        return self.security_features\n",
    "\n",
    "# Initialize our educational ML framework\n",
    "security_ml = SecurityMLEducation()\n",
    "features_df = security_ml.extract_security_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Anomaly Detection: Isolation Forest\n",
    "\n",
    "Let's start with one of the most effective and interpretable anomaly detection algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def educational_isolation_forest():\n",
    "    \"\"\"\n",
    "    Isolation Forest with complete educational explanations\n",
    "    \"\"\"\n",
    "    \n",
    "    security_ml.explain_concept(\n",
    "        \"Isolation Forest for Security Anomaly Detection\",\n",
    "        \"\"\"\n",
    "HOW ISOLATION FOREST WORKS:\n",
    "\n",
    "Imagine you're at a party trying to spot the person who doesn't belong:\n",
    "‚Ä¢ Normal people are clustered together (similar behaviors)\n",
    "‚Ä¢ Anomalous people are isolated (different behaviors)\n",
    "‚Ä¢ It's easier to separate the unusual person from the crowd\n",
    "\n",
    "ISOLATION FOREST ALGORITHM:\n",
    "1. Randomly select a feature (e.g., \"access_count\")\n",
    "2. Randomly pick a split value between min and max\n",
    "3. Separate data points based on this split\n",
    "4. Repeat until each point is isolated\n",
    "5. Anomalies get isolated faster (fewer splits needed)\n",
    "\n",
    "WHY IT WORKS FOR SECURITY:\n",
    "‚Ä¢ Attackers often have unusual access patterns\n",
    "‚Ä¢ No need to define \"normal\" behavior explicitly\n",
    "‚Ä¢ Works well with mixed data types\n",
    "‚Ä¢ Fast and scalable for large datasets\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Prepare features for ML (numerical only)\n",
    "    numerical_features = ['total_access_count', 'unique_targets_accessed', \n",
    "                         'target_diversity', 'access_method_diversity',\n",
    "                         'sensitive_data_reachable', 'roles_assumed', 'privilege_level']\n",
    "    \n",
    "    X = security_ml.security_features[numerical_features].fillna(0)\n",
    "    \n",
    "    # Scale features for better results\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    print(f\"\\nüî¢ Model Input: {X_scaled.shape[0]} users with {X_scaled.shape[1]} security features\")\n",
    "    \n",
    "    # Train Isolation Forest\n",
    "    isolation_forest = IsolationForest(\n",
    "        contamination=0.1,  # Expect 10% anomalies\n",
    "        random_state=42,\n",
    "        n_estimators=100\n",
    "    )\n",
    "    \n",
    "    # Get predictions and anomaly scores\n",
    "    predictions = isolation_forest.fit_predict(X_scaled)\n",
    "    anomaly_scores = isolation_forest.decision_function(X_scaled)\n",
    "    \n",
    "    # Add results to our dataframe\n",
    "    results_df = security_ml.security_features.copy()\n",
    "    results_df['anomaly_prediction'] = predictions  # -1 = anomaly, 1 = normal\n",
    "    results_df['anomaly_score'] = anomaly_scores    # Lower = more anomalous\n",
    "    results_df['is_anomaly'] = predictions == -1\n",
    "    \n",
    "    # Educational analysis of results\n",
    "    anomalies = results_df[results_df['is_anomaly']]\n",
    "    normal_users = results_df[~results_df['is_anomaly']]\n",
    "    \n",
    "    print(f\"\\nüéØ Isolation Forest Results:\")\n",
    "    print(f\"‚Ä¢ Total users analyzed: {len(results_df)}\")\n",
    "    print(f\"‚Ä¢ Anomalies detected: {len(anomalies)} ({len(anomalies)/len(results_df)*100:.1f}%)\")\n",
    "    print(f\"‚Ä¢ Normal users: {len(normal_users)} ({len(normal_users)/len(results_df)*100:.1f}%)\")\n",
    "    \n",
    "    if len(anomalies) > 0:\n",
    "        print(\"\\nüö® Detected Security Anomalies:\")\n",
    "        for _, user in anomalies.iterrows():\n",
    "            print(f\"\\nüîç ANOMALY: {user['user_name']} ({user['access_level']})\")\n",
    "            print(f\"   ‚Ä¢ Anomaly Score: {user['anomaly_score']:.3f} (lower = more suspicious)\")\n",
    "            print(f\"   ‚Ä¢ Access Count: {user['total_access_count']} (vs avg: {normal_users['total_access_count'].mean():.1f})\")\n",
    "            print(f\"   ‚Ä¢ Sensitive Data Access: {user['sensitive_data_reachable']} resources\")\n",
    "            print(f\"   ‚Ä¢ Roles Available: {user['roles_assumed']}\")\n",
    "            \n",
    "            # Generate explanation\n",
    "            reasons = []\n",
    "            if user['total_access_count'] > normal_users['total_access_count'].mean() + 2*normal_users['total_access_count'].std():\n",
    "                reasons.append(\"Unusually high access activity\")\n",
    "            if user['sensitive_data_reachable'] > normal_users['sensitive_data_reachable'].mean() + normal_users['sensitive_data_reachable'].std():\n",
    "                reasons.append(\"Above-average sensitive data access\")\n",
    "            if user['target_diversity'] > normal_users['target_diversity'].mean() + normal_users['target_diversity'].std():\n",
    "                reasons.append(\"Accessing diverse resource types\")\n",
    "            \n",
    "            if reasons:\n",
    "                print(f\"   ‚Ä¢ Likely reasons: {'; '.join(reasons)}\")\n",
    "            else:\n",
    "                print(f\"   ‚Ä¢ Complex pattern - requires manual investigation\")\n",
    "    \n",
    "    # Create educational visualizations\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Anomaly Score Distribution\n",
    "    ax1.hist(normal_users['anomaly_score'], bins=20, alpha=0.7, label='Normal Users', color='green')\n",
    "    ax1.hist(anomalies['anomaly_score'], bins=20, alpha=0.7, label='Anomalies', color='red')\n",
    "    ax1.set_xlabel('Anomaly Score (Lower = More Suspicious)')\n",
    "    ax1.set_ylabel('Count')\n",
    "    ax1.set_title('Anomaly Score Distribution')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Access Pattern Comparison\n",
    "    ax2.scatter(normal_users['total_access_count'], normal_users['sensitive_data_reachable'], \n",
    "               alpha=0.6, color='green', label='Normal Users')\n",
    "    ax2.scatter(anomalies['total_access_count'], anomalies['sensitive_data_reachable'], \n",
    "               alpha=0.8, color='red', s=100, label='Anomalies')\n",
    "    ax2.set_xlabel('Total Access Count')\n",
    "    ax2.set_ylabel('Sensitive Data Reachable')\n",
    "    ax2.set_title('Access Patterns: Normal vs Anomalous')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Feature Importance (manual analysis)\n",
    "    feature_importance = []\n",
    "    for feature in numerical_features:\n",
    "        if len(anomalies) > 0 and len(normal_users) > 0:\n",
    "            normal_mean = normal_users[feature].mean()\n",
    "            anomaly_mean = anomalies[feature].mean()\n",
    "            difference = abs(anomaly_mean - normal_mean) / (normal_mean + 0.001)\n",
    "            feature_importance.append((feature, difference))\n",
    "    \n",
    "    feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "    features, importances = zip(*feature_importance)\n",
    "    \n",
    "    ax3.barh(features, importances, color='skyblue')\n",
    "    ax3.set_xlabel('Relative Difference (Anomaly vs Normal)')\n",
    "    ax3.set_title('Most Discriminative Features')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Privilege Level Analysis\n",
    "    privilege_anomaly_rate = results_df.groupby(['access_level', 'is_anomaly']).size().unstack(fill_value=0)\n",
    "    if not privilege_anomaly_rate.empty:\n",
    "        privilege_anomaly_rate.plot(kind='bar', ax=ax4, color=['green', 'red'])\n",
    "        ax4.set_title('Anomaly Rate by Privilege Level')\n",
    "        ax4.set_xlabel('Access Level')\n",
    "        ax4.set_ylabel('Count')\n",
    "        ax4.legend(['Normal', 'Anomaly'])\n",
    "        ax4.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Educational summary\n",
    "    print(f\"\\nüéì Educational Insights:\")\n",
    "    print(f\"‚Ä¢ Isolation Forest identified users with unusual access patterns\")\n",
    "    print(f\"‚Ä¢ Lower anomaly scores indicate higher suspicion levels\")\n",
    "    print(f\"‚Ä¢ Most discriminative feature: {features[0] if features else 'N/A'}\")\n",
    "    print(f\"‚Ä¢ Consider investigating anomalies for potential security risks\")\n",
    "    \n",
    "    if len(anomalies) > 0:\n",
    "        print(f\"\\nüîç Investigation Priorities:\")\n",
    "        sorted_anomalies = anomalies.sort_values('anomaly_score')\n",
    "        for i, (_, user) in enumerate(sorted_anomalies.head(3).iterrows(), 1):\n",
    "            print(f\"{i}. {user['user_name']}: Score {user['anomaly_score']:.3f}\")\n",
    "    \n",
    "    return results_df, isolation_forest\n",
    "\n",
    "# Run the educational Isolation Forest analysis\n",
    "anomaly_results, trained_model = educational_isolation_forest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Clustering Analysis: Finding User Behavior Groups\n",
    "\n",
    "Sometimes anomalies aren't individual outliers, but belong to suspicious groups. Let's use clustering to find behavior patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def educational_clustering_analysis():\n",
    "    \"\"\"\n",
    "    DBSCAN clustering with educational explanations\n",
    "    \"\"\"\n",
    "    \n",
    "    security_ml.explain_concept(\n",
    "        \"Clustering for Security Behavior Analysis\",\n",
    "        \"\"\"\n",
    "WHY CLUSTERING FOR SECURITY?\n",
    "\n",
    "Real-world scenario: You have 1000 users. Instead of analyzing each\n",
    "individually, clustering groups them by similar behavior:\n",
    "\n",
    "‚Ä¢ Group 1: Normal office workers (low access, standard hours)\n",
    "‚Ä¢ Group 2: System administrators (high access, varied hours)\n",
    "‚Ä¢ Group 3: Compromised accounts (unusual patterns)\n",
    "‚Ä¢ Outliers: Potentially malicious or misconfigured users\n",
    "\n",
    "DBSCAN ALGORITHM:\n",
    "‚Ä¢ Density-Based Spatial Clustering\n",
    "‚Ä¢ Finds clusters of similar users based on behavior\n",
    "‚Ä¢ Automatically identifies outliers (noise points)\n",
    "‚Ä¢ No need to specify number of clusters in advance\n",
    "\n",
    "SECURITY APPLICATIONS:\n",
    "‚Ä¢ Identify user behavior groups\n",
    "‚Ä¢ Find isolated suspicious users\n",
    "‚Ä¢ Baseline normal behavior per group\n",
    "‚Ä¢ Detect coordinated attacks (multiple users, similar pattern)\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Prepare data for clustering\n",
    "    numerical_features = ['total_access_count', 'unique_targets_accessed', \n",
    "                         'target_diversity', 'access_method_diversity',\n",
    "                         'sensitive_data_reachable', 'roles_assumed', 'privilege_level']\n",
    "    \n",
    "    X = security_ml.security_features[numerical_features].fillna(0)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Apply DBSCAN clustering\n",
    "    dbscan = DBSCAN(\n",
    "        eps=0.8,        # Distance threshold for grouping\n",
    "        min_samples=2   # Minimum users per cluster\n",
    "    )\n",
    "    \n",
    "    cluster_labels = dbscan.fit_predict(X_scaled)\n",
    "    \n",
    "    # Add cluster results to dataframe\n",
    "    cluster_df = security_ml.security_features.copy()\n",
    "    cluster_df['cluster'] = cluster_labels\n",
    "    cluster_df['is_outlier'] = cluster_labels == -1\n",
    "    \n",
    "    # Analyze clusters\n",
    "    unique_clusters = set(cluster_labels)\n",
    "    outliers = cluster_df[cluster_df['is_outlier']]\n",
    "    clustered_users = cluster_df[~cluster_df['is_outlier']]\n",
    "    \n",
    "    print(f\"\\nüéØ Clustering Results:\")\n",
    "    print(f\"‚Ä¢ Total users: {len(cluster_df)}\")\n",
    "    print(f\"‚Ä¢ Clusters found: {len(unique_clusters) - (1 if -1 in unique_clusters else 0)}\")\n",
    "    print(f\"‚Ä¢ Outliers (suspicious): {len(outliers)} ({len(outliers)/len(cluster_df)*100:.1f}%)\")\n",
    "    print(f\"‚Ä¢ Users in clusters: {len(clustered_users)}\")\n",
    "    \n",
    "    # Analyze each cluster\n",
    "    print(\"\\nüîç Cluster Analysis:\")\n",
    "    for cluster_id in sorted(unique_clusters):\n",
    "        if cluster_id == -1:\n",
    "            continue  # Handle outliers separately\n",
    "        \n",
    "        cluster_users = cluster_df[cluster_df['cluster'] == cluster_id]\n",
    "        if len(cluster_users) == 0:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nüìä Cluster {cluster_id} ({len(cluster_users)} users):\")\n",
    "        \n",
    "        # Cluster characteristics\n",
    "        avg_access = cluster_users['total_access_count'].mean()\n",
    "        avg_sensitive = cluster_users['sensitive_data_reachable'].mean()\n",
    "        common_level = cluster_users['access_level'].mode()[0] if not cluster_users['access_level'].mode().empty else 'Mixed'\n",
    "        \n",
    "        print(f\"   ‚Ä¢ Average access count: {avg_access:.1f}\")\n",
    "        print(f\"   ‚Ä¢ Sensitive data access: {avg_sensitive:.1f}\")\n",
    "        print(f\"   ‚Ä¢ Common access level: {common_level}\")\n",
    "        print(f\"   ‚Ä¢ Members: {', '.join(cluster_users['user_name'].tolist())}\")\n",
    "        \n",
    "        # Cluster interpretation\n",
    "        if avg_access < 2 and avg_sensitive < 1:\n",
    "            cluster_type = \"üü¢ Normal/Low-Activity Users\"\n",
    "        elif avg_access > 5 and avg_sensitive > 2:\n",
    "            cluster_type = \"üü° High-Activity/Privileged Users\"\n",
    "        elif common_level == 'administrator':\n",
    "            cluster_type = \"üîµ Administrator Group\"\n",
    "        else:\n",
    "            cluster_type = \"üü† Mixed Activity Group\"\n",
    "        \n",
    "        print(f\"   ‚Ä¢ Classification: {cluster_type}\")\n",
    "    \n",
    "    # Analyze outliers (most important for security)\n",
    "    if len(outliers) > 0:\n",
    "        print(f\"\\nüö® Security Outliers (Require Investigation):\")\n",
    "        for _, user in outliers.iterrows():\n",
    "            print(f\"\\nüîç OUTLIER: {user['user_name']} ({user['access_level']})\")\n",
    "            print(f\"   ‚Ä¢ Access Count: {user['total_access_count']}\")\n",
    "            print(f\"   ‚Ä¢ Sensitive Access: {user['sensitive_data_reachable']}\")\n",
    "            print(f\"   ‚Ä¢ Target Diversity: {user['target_diversity']}\")\n",
    "            print(f\"   ‚Ä¢ Roles: {user['roles_assumed']}\")\n",
    "            \n",
    "            # Why this user is an outlier\n",
    "            reasons = []\n",
    "            overall_avg_access = cluster_df['total_access_count'].mean()\n",
    "            overall_avg_sensitive = cluster_df['sensitive_data_reachable'].mean()\n",
    "            \n",
    "            if user['total_access_count'] > overall_avg_access * 2:\n",
    "                reasons.append(\"Extremely high access activity\")\n",
    "            if user['sensitive_data_reachable'] > overall_avg_sensitive * 2:\n",
    "                reasons.append(\"Unusual sensitive data access\")\n",
    "            if user['target_diversity'] > cluster_df['target_diversity'].mean() * 1.5:\n",
    "                reasons.append(\"Accessing unusually diverse resources\")\n",
    "            \n",
    "            if reasons:\n",
    "                print(f\"   ‚Ä¢ Outlier reasons: {'; '.join(reasons)}\")\n",
    "                \n",
    "                # Risk assessment\n",
    "                risk_score = len(reasons)\n",
    "                if risk_score >= 3:\n",
    "                    risk_level = \"üî¥ HIGH RISK\"\n",
    "                elif risk_score >= 2:\n",
    "                    risk_level = \"üü† MEDIUM RISK\"\n",
    "                else:\n",
    "                    risk_level = \"üü° LOW RISK\"\n",
    "                print(f\"   ‚Ä¢ Risk Assessment: {risk_level}\")\n",
    "    \n",
    "    # Visualization\n",
    "    if X_scaled.shape[1] >= 2:\n",
    "        # Use PCA to visualize high-dimensional clusters in 2D\n",
    "        pca = PCA(n_components=2)\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "        \n",
    "        plt.figure(figsize=(14, 10))\n",
    "        \n",
    "        # Plot clusters\n",
    "        unique_labels = set(cluster_labels)\n",
    "        colors = plt.cm.Set1(np.linspace(0, 1, len(unique_labels)))\n",
    "        \n",
    "        for k, col in zip(unique_labels, colors):\n",
    "            if k == -1:\n",
    "                # Outliers in black\n",
    "                col = 'black'\n",
    "                marker = 'x'\n",
    "                size = 100\n",
    "                label = f'Outliers ({np.sum(cluster_labels == k)} users)'\n",
    "            else:\n",
    "                marker = 'o'\n",
    "                size = 60\n",
    "                label = f'Cluster {k} ({np.sum(cluster_labels == k)} users)'\n",
    "            \n",
    "            class_member_mask = (cluster_labels == k)\n",
    "            xy = X_pca[class_member_mask]\n",
    "            \n",
    "            plt.scatter(xy[:, 0], xy[:, 1], c=[col], marker=marker, s=size, alpha=0.8, label=label)\n",
    "        \n",
    "        plt.xlabel(f'First Principal Component ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "        plt.ylabel(f'Second Principal Component ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "        plt.title('User Behavior Clustering\\n(Outliers = Potential Security Risks)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add educational annotations\n",
    "        if len(outliers) > 0:\n",
    "            plt.text(0.02, 0.98, \n",
    "                    f'üö® {len(outliers)} outliers detected\\n'\n",
    "                    f'Require security investigation',\n",
    "                    transform=plt.gca().transAxes,\n",
    "                    verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='red', alpha=0.3))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Educational summary\n",
    "    print(f\"\\nüéì Clustering Insights for Security Teams:\")\n",
    "    print(f\"‚Ä¢ Clustering helps establish behavior baselines for different user types\")\n",
    "    print(f\"‚Ä¢ Outliers are automatically flagged for investigation\")\n",
    "    print(f\"‚Ä¢ Each cluster can have tailored security policies\")\n",
    "    print(f\"‚Ä¢ Monitor for users changing clusters (behavior drift)\")\n",
    "    \n",
    "    if len(outliers) > 0:\n",
    "        high_risk_outliers = len([u for _, u in outliers.iterrows() \n",
    "                                 if u['total_access_count'] > cluster_df['total_access_count'].mean() * 2])\n",
    "        print(f\"\\n‚ö†Ô∏è  Immediate Actions Required:\")\n",
    "        print(f\"‚Ä¢ Investigate {len(outliers)} outlier accounts\")\n",
    "        print(f\"‚Ä¢ {high_risk_outliers} users show high-risk patterns\")\n",
    "        print(f\"‚Ä¢ Consider additional monitoring for outlier users\")\n",
    "    \n",
    "    return cluster_df, dbscan\n",
    "\n",
    "# Run the educational clustering analysis\n",
    "cluster_results, cluster_model = educational_clustering_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Local Outlier Factor: Context-Aware Anomaly Detection\n",
    "\n",
    "Sometimes a user isn't globally anomalous, but unusual compared to their local neighborhood. LOF finds these subtle anomalies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def educational_local_outlier_factor():\n",
    "    \"\"\"\n",
    "    Local Outlier Factor with detailed explanations\n",
    "    \"\"\"\n",
    "    \n",
    "    security_ml.explain_concept(\n",
    "        \"Local Outlier Factor (LOF) for Context-Aware Detection\",\n",
    "        \"\"\"\n",
    "WHY LOCAL OUTLIER FACTOR?\n",
    "\n",
    "Imagine two scenarios:\n",
    "1. A developer accessing 10 systems (normal for developers)\n",
    "2. A marketing person accessing 10 systems (unusual for marketing)\n",
    "\n",
    "Global methods might miss #2 because 10 isn't globally unusual.\n",
    "LOF compares each user to their \"local neighborhood\" of similar users.\n",
    "\n",
    "HOW LOF WORKS:\n",
    "1. For each user, find their k nearest neighbors\n",
    "2. Calculate local density (how close are neighbors?)\n",
    "3. Compare user's density to neighbors' densities\n",
    "4. If user is in a sparse area while neighbors are dense ‚Üí outlier\n",
    "\n",
    "SECURITY ADVANTAGE:\n",
    "‚Ä¢ Detects users unusual within their role/group\n",
    "‚Ä¢ Finds subtle deviations from peer behavior\n",
    "‚Ä¢ Good for insider threat detection\n",
    "‚Ä¢ Accounts for legitimate differences between user types\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Prepare data\n",
    "    numerical_features = ['total_access_count', 'unique_targets_accessed', \n",
    "                         'target_diversity', 'access_method_diversity',\n",
    "                         'sensitive_data_reachable', 'roles_assumed', 'privilege_level']\n",
    "    \n",
    "    X = security_ml.security_features[numerical_features].fillna(0)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Apply Local Outlier Factor\n",
    "    lof = LocalOutlierFactor(\n",
    "        n_neighbors=min(5, len(X) - 1),  # Adjust based on dataset size\n",
    "        contamination=0.15  # Expect 15% local outliers\n",
    "    )\n",
    "    \n",
    "    predictions = lof.fit_predict(X_scaled)\n",
    "    outlier_scores = lof.negative_outlier_factor_\n",
    "    \n",
    "    # Create results dataframe\n",
    "    lof_df = security_ml.security_features.copy()\n",
    "    lof_df['lof_prediction'] = predictions  # -1 = outlier, 1 = normal\n",
    "    lof_df['lof_score'] = outlier_scores    # More negative = more outlying\n",
    "    lof_df['is_local_outlier'] = predictions == -1\n",
    "    \n",
    "    # Analysis\n",
    "    local_outliers = lof_df[lof_df['is_local_outlier']]\n",
    "    normal_users = lof_df[~lof_df['is_local_outlier']]\n",
    "    \n",
    "    print(f\"\\nüéØ Local Outlier Factor Results:\")\n",
    "    print(f\"‚Ä¢ Total users: {len(lof_df)}\")\n",
    "    print(f\"‚Ä¢ Local outliers: {len(local_outliers)} ({len(local_outliers)/len(lof_df)*100:.1f}%)\")\n",
    "    print(f\"‚Ä¢ Normal in context: {len(normal_users)}\")\n",
    "    \n",
    "    if len(local_outliers) > 0:\n",
    "        print(\"\\nüîç Local Context Anomalies:\")\n",
    "        \n",
    "        # Sort by most anomalous (most negative LOF score)\n",
    "        sorted_outliers = local_outliers.sort_values('lof_score')\n",
    "        \n",
    "        for _, user in sorted_outliers.iterrows():\n",
    "            print(f\"\\nüö® LOCAL OUTLIER: {user['user_name']} ({user['access_level']})\")\n",
    "            print(f\"   ‚Ä¢ LOF Score: {user['lof_score']:.3f} (more negative = more unusual)\")\n",
    "            \n",
    "            # Find similar users for context\n",
    "            same_level_users = lof_df[lof_df['access_level'] == user['access_level']]\n",
    "            if len(same_level_users) > 1:\n",
    "                level_avg_access = same_level_users['total_access_count'].mean()\n",
    "                level_avg_sensitive = same_level_users['sensitive_data_reachable'].mean()\n",
    "                \n",
    "                print(f\"   ‚Ä¢ Access vs peers: {user['total_access_count']} (avg: {level_avg_access:.1f})\")\n",
    "                print(f\"   ‚Ä¢ Sensitive access vs peers: {user['sensitive_data_reachable']} (avg: {level_avg_sensitive:.1f})\")\n",
    "                \n",
    "                # Context-specific analysis\n",
    "                context_reasons = []\n",
    "                if user['total_access_count'] > level_avg_access * 1.5:\n",
    "                    context_reasons.append(f\"High access for {user['access_level']} role\")\n",
    "                if user['sensitive_data_reachable'] > level_avg_sensitive * 1.5:\n",
    "                    context_reasons.append(f\"Above-average sensitive access for role\")\n",
    "                if user['target_diversity'] > same_level_users['target_diversity'].mean() * 1.3:\n",
    "                    context_reasons.append(f\"Accessing diverse resources for role\")\n",
    "                \n",
    "                if context_reasons:\n",
    "                    print(f\"   ‚Ä¢ Context reasons: {'; '.join(context_reasons)}\")\n",
    "                else:\n",
    "                    print(f\"   ‚Ä¢ Subtle behavioral pattern - requires detailed investigation\")\n",
    "    \n",
    "    # Compare LOF with global anomaly detection\n",
    "    if 'is_anomaly' in anomaly_results.columns:\n",
    "        # Merge with previous Isolation Forest results\n",
    "        comparison_df = lof_df.merge(\n",
    "            anomaly_results[['user_name', 'is_anomaly']], \n",
    "            on='user_name', \n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Analysis of different detection methods\n",
    "        both_methods = comparison_df['is_anomaly'] & comparison_df['is_local_outlier']\n",
    "        only_global = comparison_df['is_anomaly'] & ~comparison_df['is_local_outlier']\n",
    "        only_local = ~comparison_df['is_anomaly'] & comparison_df['is_local_outlier']\n",
    "        \n",
    "        print(f\"\\nüîç Detection Method Comparison:\")\n",
    "        print(f\"‚Ä¢ Both methods agree: {both_methods.sum()} users (highest confidence)\")\n",
    "        print(f\"‚Ä¢ Only global anomaly: {only_global.sum()} users (globally unusual)\")\n",
    "        print(f\"‚Ä¢ Only local outlier: {only_local.sum()} users (contextually unusual)\")\n",
    "        \n",
    "        if only_local.sum() > 0:\n",
    "            print(f\"\\nüí° LOF-Specific Detections (missed by global methods):\")\n",
    "            local_only_users = comparison_df[only_local]\n",
    "            for _, user in local_only_users.iterrows():\n",
    "                print(f\"   ‚Ä¢ {user['user_name']}: Unusual for {user['access_level']} role\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. LOF Score Distribution\n",
    "    ax1.hist(normal_users['lof_score'], bins=20, alpha=0.7, label='Normal Users', color='green')\n",
    "    if len(local_outliers) > 0:\n",
    "        ax1.hist(local_outliers['lof_score'], bins=20, alpha=0.7, label='Local Outliers', color='red')\n",
    "    ax1.axvline(-1, color='orange', linestyle='--', label='Typical Threshold')\n",
    "    ax1.set_xlabel('LOF Score (More Negative = More Unusual)')\n",
    "    ax1.set_ylabel('Count')\n",
    "    ax1.set_title('Local Outlier Factor Score Distribution')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Context-based analysis by access level\n",
    "    access_levels = lof_df['access_level'].unique()\n",
    "    for i, level in enumerate(access_levels):\n",
    "        level_data = lof_df[lof_df['access_level'] == level]\n",
    "        color = ['blue', 'green', 'orange', 'purple'][i % 4]\n",
    "        ax2.scatter(\n",
    "            level_data['total_access_count'], \n",
    "            level_data['sensitive_data_reachable'],\n",
    "            alpha=0.6, \n",
    "            label=level,\n",
    "            color=color\n",
    "        )\n",
    "    \n",
    "    # Highlight local outliers\n",
    "    if len(local_outliers) > 0:\n",
    "        ax2.scatter(\n",
    "            local_outliers['total_access_count'],\n",
    "            local_outliers['sensitive_data_reachable'],\n",
    "            color='red',\n",
    "            s=200,\n",
    "            alpha=0.8,\n",
    "            marker='x',\n",
    "            label='Local Outliers'\n",
    "        )\n",
    "    \n",
    "    ax2.set_xlabel('Total Access Count')\n",
    "    ax2.set_ylabel('Sensitive Data Reachable')\n",
    "    ax2.set_title('User Behavior by Access Level\\n(X marks = Local outliers)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. LOF vs other features\n",
    "    ax3.scatter(lof_df['lof_score'], lof_df['total_access_count'], alpha=0.6, color='blue')\n",
    "    if len(local_outliers) > 0:\n",
    "        ax3.scatter(local_outliers['lof_score'], local_outliers['total_access_count'], \n",
    "                   color='red', s=100, alpha=0.8, label='Local Outliers')\n",
    "    ax3.set_xlabel('LOF Score')\n",
    "    ax3.set_ylabel('Total Access Count')\n",
    "    ax3.set_title('LOF Score vs Access Activity')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    if len(local_outliers) > 0:\n",
    "        ax3.legend()\n",
    "    \n",
    "    # 4. Detection method comparison (if available)\n",
    "    if 'is_anomaly' in locals() and comparison_df is not None:\n",
    "        detection_counts = [\n",
    "            both_methods.sum(),\n",
    "            only_global.sum(), \n",
    "            only_local.sum(),\n",
    "            len(comparison_df) - both_methods.sum() - only_global.sum() - only_local.sum()\n",
    "        ]\n",
    "        labels = ['Both Methods', 'Only Global', 'Only Local', 'Neither']\n",
    "        colors = ['red', 'orange', 'yellow', 'green']\n",
    "        \n",
    "        ax4.pie(detection_counts, labels=labels, colors=colors, autopct='%1.1f%%')\n",
    "        ax4.set_title('Detection Method Overlap')\n",
    "    else:\n",
    "        ax4.text(0.5, 0.5, 'No comparison data\\navailable', \n",
    "                ha='center', va='center', transform=ax4.transAxes)\n",
    "        ax4.set_title('Method Comparison')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Educational insights\n",
    "    print(f\"\\nüéì Local Outlier Factor Insights:\")\n",
    "    print(f\"‚Ä¢ LOF finds users unusual within their peer group/role\")\n",
    "    print(f\"‚Ä¢ Particularly good for insider threat detection\")\n",
    "    print(f\"‚Ä¢ Complements global anomaly detection methods\")\n",
    "    print(f\"‚Ä¢ Consider role-based security policies for different user groups\")\n",
    "    \n",
    "    if len(local_outliers) > 0:\n",
    "        worst_outlier = sorted_outliers.iloc[0]\n",
    "        print(f\"\\nüîç Priority Investigation:\")\n",
    "        print(f\"‚Ä¢ Most unusual user: {worst_outlier['user_name']} (score: {worst_outlier['lof_score']:.3f})\")\n",
    "        print(f\"‚Ä¢ Recommend immediate review of access patterns and recent activity\")\n",
    "    \n",
    "    return lof_df, lof\n",
    "\n",
    "# Run the Local Outlier Factor analysis\n",
    "lof_results, lof_model = educational_local_outlier_factor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Comprehensive ML Security Dashboard\n",
    "\n",
    "Let's combine all our analyses into a comprehensive security dashboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ml_security_dashboard():\n",
    "    \"\"\"\n",
    "    Comprehensive ML-based security analysis dashboard\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üéØ COMPREHENSIVE ML SECURITY ANALYSIS DASHBOARD\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Combine all analyses\n",
    "    dashboard_df = security_ml.security_features.copy()\n",
    "    \n",
    "    # Add results from different methods\n",
    "    if 'is_anomaly' in anomaly_results.columns:\n",
    "        dashboard_df = dashboard_df.merge(\n",
    "            anomaly_results[['user_name', 'is_anomaly', 'anomaly_score']], \n",
    "            on='user_name', how='left'\n",
    "        )\n",
    "    \n",
    "    if 'is_outlier' in cluster_results.columns:\n",
    "        dashboard_df = dashboard_df.merge(\n",
    "            cluster_results[['user_name', 'is_outlier', 'cluster']], \n",
    "            on='user_name', how='left'\n",
    "        )\n",
    "    \n",
    "    if 'is_local_outlier' in lof_results.columns:\n",
    "        dashboard_df = dashboard_df.merge(\n",
    "            lof_results[['user_name', 'is_local_outlier', 'lof_score']], \n",
    "            on='user_name', how='left'\n",
    "        )\n",
    "    \n",
    "    # Calculate composite risk score\n",
    "    dashboard_df['risk_score'] = 0\n",
    "    \n",
    "    if 'is_anomaly' in dashboard_df.columns:\n",
    "        dashboard_df['risk_score'] += dashboard_df['is_anomaly'].astype(int) * 3\n",
    "    if 'is_outlier' in dashboard_df.columns:\n",
    "        dashboard_df['risk_score'] += dashboard_df['is_outlier'].astype(int) * 2\n",
    "    if 'is_local_outlier' in dashboard_df.columns:\n",
    "        dashboard_df['risk_score'] += dashboard_df['is_local_outlier'].astype(int) * 2\n",
    "    \n",
    "    # Risk categorization\n",
    "    dashboard_df['risk_category'] = dashboard_df['risk_score'].apply(\n",
    "        lambda x: 'CRITICAL' if x >= 6 else \n",
    "                 'HIGH' if x >= 4 else \n",
    "                 'MEDIUM' if x >= 2 else \n",
    "                 'LOW'\n",
    "    )\n",
    "    \n",
    "    # Security Dashboard Summary\n",
    "    print(f\"\\nüìã EXECUTIVE SECURITY SUMMARY:\")\n",
    "    print(f\"‚Ä¢ Total users analyzed: {len(dashboard_df)}\")\n",
    "    \n",
    "    risk_distribution = dashboard_df['risk_category'].value_counts()\n",
    "    for risk_level in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']:\n",
    "        count = risk_distribution.get(risk_level, 0)\n",
    "        percentage = (count / len(dashboard_df)) * 100\n",
    "        icon = {'CRITICAL': 'üî¥', 'HIGH': 'üü†', 'MEDIUM': 'üü°', 'LOW': 'üü¢'}[risk_level]\n",
    "        print(f\"‚Ä¢ {icon} {risk_level} Risk: {count} users ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Detailed risk analysis\n",
    "    high_risk_users = dashboard_df[dashboard_df['risk_category'].isin(['CRITICAL', 'HIGH'])]\n",
    "    \n",
    "    if len(high_risk_users) > 0:\n",
    "        print(f\"\\nüö® HIGH-PRIORITY SECURITY ALERTS:\")\n",
    "        \n",
    "        sorted_high_risk = high_risk_users.sort_values('risk_score', ascending=False)\n",
    "        \n",
    "        for _, user in sorted_high_risk.head(5).iterrows():\n",
    "            risk_icon = 'üî¥' if user['risk_category'] == 'CRITICAL' else 'üü†'\n",
    "            \n",
    "            print(f\"\\n{risk_icon} {user['risk_category']} RISK: {user['user_name']} ({user['access_level']})\")\n",
    "            print(f\"   ‚Ä¢ Composite Risk Score: {user['risk_score']}/7\")\n",
    "            \n",
    "            # Detection breakdown\n",
    "            detections = []\n",
    "            if user.get('is_anomaly', False):\n",
    "                detections.append(f\"Global Anomaly (score: {user.get('anomaly_score', 'N/A'):.3f})\")\n",
    "            if user.get('is_outlier', False):\n",
    "                detections.append(f\"Clustering Outlier (cluster: {user.get('cluster', 'N/A')})\")\n",
    "            if user.get('is_local_outlier', False):\n",
    "                detections.append(f\"Local Outlier (score: {user.get('lof_score', 'N/A'):.3f})\")\n",
    "            \n",
    "            if detections:\n",
    "                print(f\"   ‚Ä¢ Detection methods: {'; '.join(detections)}\")\n",
    "            \n",
    "            # Key metrics\n",
    "            print(f\"   ‚Ä¢ Access Activity: {user['total_access_count']} resources\")\n",
    "            print(f\"   ‚Ä¢ Sensitive Data Access: {user['sensitive_data_reachable']} resources\")\n",
    "            print(f\"   ‚Ä¢ Available Roles: {user['roles_assumed']}\")\n",
    "            \n",
    "            # Recommended actions\n",
    "            recommendations = []\n",
    "            if user['risk_score'] >= 6:\n",
    "                recommendations.extend([\n",
    "                    \"Immediate investigation required\",\n",
    "                    \"Consider temporary access restrictions\",\n",
    "                    \"Review recent activity logs\"\n",
    "                ])\n",
    "            elif user['risk_score'] >= 4:\n",
    "                recommendations.extend([\n",
    "                    \"Schedule security review within 24 hours\",\n",
    "                    \"Increase monitoring frequency\",\n",
    "                    \"Verify legitimate business need for access\"\n",
    "                ])\n",
    "            \n",
    "            if recommendations:\n",
    "                print(f\"   ‚Ä¢ Recommended Actions: {'; '.join(recommendations)}\")\n",
    "    \n",
    "    # Method effectiveness analysis\n",
    "    print(f\"\\nüîç ML METHOD EFFECTIVENESS ANALYSIS:\")\n",
    "    \n",
    "    method_stats = {}\n",
    "    if 'is_anomaly' in dashboard_df.columns:\n",
    "        method_stats['Isolation Forest'] = dashboard_df['is_anomaly'].sum()\n",
    "    if 'is_outlier' in dashboard_df.columns:\n",
    "        method_stats['DBSCAN Clustering'] = dashboard_df['is_outlier'].sum()\n",
    "    if 'is_local_outlier' in dashboard_df.columns:\n",
    "        method_stats['Local Outlier Factor'] = dashboard_df['is_local_outlier'].sum()\n",
    "    \n",
    "    for method, count in method_stats.items():\n",
    "        percentage = (count / len(dashboard_df)) * 100\n",
    "        print(f\"‚Ä¢ {method}: {count} detections ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Risk Score Distribution',\n",
    "            'Detection Method Comparison', \n",
    "            'Access Patterns by Risk Level',\n",
    "            'ML Method Effectiveness'\n",
    "        ),\n",
    "        specs=[[{\"type\": \"histogram\"}, {\"type\": \"bar\"}],\n",
    "               [{\"type\": \"scatter\"}, {\"type\": \"bar\"}]]\n",
    "    )\n",
    "    \n",
    "    # Risk score distribution\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=dashboard_df['risk_score'],\n",
    "            name='Risk Score',\n",
    "            marker_color='red',\n",
    "            opacity=0.7\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Risk category distribution\n",
    "    risk_counts = [risk_distribution.get(level, 0) for level in ['LOW', 'MEDIUM', 'HIGH', 'CRITICAL']]\n",
    "    risk_colors = ['green', 'yellow', 'orange', 'red']\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=['LOW', 'MEDIUM', 'HIGH', 'CRITICAL'],\n",
    "            y=risk_counts,\n",
    "            name='Risk Categories',\n",
    "            marker_color=risk_colors\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Access patterns by risk\n",
    "    risk_color_map = {'LOW': 'green', 'MEDIUM': 'yellow', 'HIGH': 'orange', 'CRITICAL': 'red'}\n",
    "    \n",
    "    for risk_level in dashboard_df['risk_category'].unique():\n",
    "        risk_data = dashboard_df[dashboard_df['risk_category'] == risk_level]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=risk_data['total_access_count'],\n",
    "                y=risk_data['sensitive_data_reachable'],\n",
    "                mode='markers',\n",
    "                name=f'{risk_level} Risk',\n",
    "                marker=dict(\n",
    "                    color=risk_color_map.get(risk_level, 'blue'),\n",
    "                    size=8,\n",
    "                    opacity=0.7\n",
    "                )\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "    \n",
    "    # Method effectiveness\n",
    "    methods = list(method_stats.keys())\n",
    "    counts = list(method_stats.values())\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=methods,\n",
    "            y=counts,\n",
    "            name='Detection Count',\n",
    "            marker_color='skyblue'\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_text=\"ü§ñ ML Security Analysis Dashboard\",\n",
    "        showlegend=True,\n",
    "        height=800\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Security recommendations\n",
    "    print(f\"\\nüéì STRATEGIC SECURITY RECOMMENDATIONS:\")\n",
    "    print(f\"\\nüîß Immediate Actions:\")\n",
    "    print(f\"‚Ä¢ Investigate {len(high_risk_users)} high-risk user accounts\")\n",
    "    print(f\"‚Ä¢ Review access patterns for users with risk score ‚â• 4\")\n",
    "    print(f\"‚Ä¢ Implement additional monitoring for detected anomalies\")\n",
    "    \n",
    "    print(f\"\\nüìä Long-term Improvements:\")\n",
    "    print(f\"‚Ä¢ Deploy automated ML-based anomaly detection\")\n",
    "    print(f\"‚Ä¢ Establish behavioral baselines for different user roles\")\n",
    "    print(f\"‚Ä¢ Create role-based access policies based on clustering results\")\n",
    "    print(f\"‚Ä¢ Implement real-time scoring for new user activities\")\n",
    "    \n",
    "    print(f\"\\nüîç Monitoring Strategy:\")\n",
    "    print(f\"‚Ä¢ Set up alerts for risk scores ‚â• 4\")\n",
    "    print(f\"‚Ä¢ Weekly review of users changing risk categories\")\n",
    "    print(f\"‚Ä¢ Monthly retraining of ML models with new data\")\n",
    "    print(f\"‚Ä¢ Quarterly validation of detection effectiveness\")\n",
    "    \n",
    "    return dashboard_df\n",
    "\n",
    "# Create the comprehensive dashboard\n",
    "security_dashboard = create_ml_security_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Advanced Challenge: Build Your Own Security ML Model\n",
    "\n",
    "Apply everything you've learned to create a custom security detection model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADVANCED ML CHALLENGE: Custom Security Model\n",
    "print(\"ü§ñ ADVANCED ML CHALLENGE: Build Your Custom Security Model\")\n",
    "print(\"=\"*65)\n",
    "print()\n",
    "print(\"üéØ YOUR MISSION:\")\n",
    "print(\"Create a machine learning model that identifies users most likely\")\n",
    "print(\"to be involved in a data breach based on their access patterns.\")\n",
    "print()\n",
    "print(\"üìã REQUIREMENTS:\")\n",
    "print(\"1. Choose appropriate features from our security dataset\")\n",
    "print(\"2. Select and configure an ML algorithm\")\n",
    "print(\"3. Train and evaluate your model\")\n",
    "print(\"4. Interpret and explain your results\")\n",
    "print(\"5. Provide actionable security recommendations\")\n",
    "print()\n",
    "print(\"üí° AVAILABLE FEATURES:\")\n",
    "feature_descriptions = {\n",
    "    'total_access_count': 'Total number of resources accessed',\n",
    "    'unique_targets_accessed': 'Number of different resources accessed', \n",
    "    'target_diversity': 'Types of resources accessed',\n",
    "    'access_method_diversity': 'Different access methods used',\n",
    "    'sensitive_data_reachable': 'Sensitive resources accessible',\n",
    "    'roles_assumed': 'Number of privilege escalation paths',\n",
    "    'privilege_level': 'Numerical privilege ranking'\n",
    "}\n",
    "\n",
    "for feature, description in feature_descriptions.items():\n",
    "    print(f\"‚Ä¢ {feature}: {description}\")\n",
    "\n",
    "print()\n",
    "print(\"üß† CHALLENGE WORKSPACE:\")\n",
    "print(\"Complete the functions below to build your model!\")\n",
    "\n",
    "def student_feature_engineering(df):\n",
    "    \"\"\"\n",
    "    YOUR TASK: Create additional security-relevant features\n",
    "    \n",
    "    Ideas:\n",
    "    - Risk ratios (sensitive_access / total_access)\n",
    "    - Privilege escalation potential\n",
    "    - Access pattern irregularity scores\n",
    "    \"\"\"\n",
    "    \n",
    "    # STUDENT CODE HERE:\n",
    "    enhanced_df = df.copy()\n",
    "    \n",
    "    # Example: Risk ratio feature\n",
    "    enhanced_df['risk_ratio'] = (\n",
    "        enhanced_df['sensitive_data_reachable'] / \n",
    "        (enhanced_df['total_access_count'] + 1)  # +1 to avoid division by zero\n",
    "    )\n",
    "    \n",
    "    # Example: Privilege escalation score\n",
    "    enhanced_df['escalation_potential'] = (\n",
    "        enhanced_df['roles_assumed'] * enhanced_df['privilege_level']\n",
    "    )\n",
    "    \n",
    "    # Add your own features here!\n",
    "    # enhanced_df['your_feature'] = ...\n",
    "    \n",
    "    return enhanced_df\n",
    "\n",
    "def student_model_selection_and_training(X, feature_names):\n",
    "    \"\"\"\n",
    "    YOUR TASK: Choose and train an appropriate ML model\n",
    "    \n",
    "    Consider:\n",
    "    - Which algorithm best fits this security problem?\n",
    "    - How to handle the unsupervised nature of the data?\n",
    "    - What parameters work best for security detection?\n",
    "    \"\"\"\n",
    "    \n",
    "    # STUDENT CODE HERE:\n",
    "    from sklearn.ensemble import IsolationForest\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Choose your model - try different algorithms!\n",
    "    # Options: IsolationForest, LocalOutlierFactor, OneClassSVM, etc.\n",
    "    model = IsolationForest(\n",
    "        contamination=0.12,  # Adjust based on expected breach rate\n",
    "        random_state=42,\n",
    "        n_estimators=200  # More trees for better detection\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    predictions = model.fit_predict(X_scaled)\n",
    "    scores = model.decision_function(X_scaled)\n",
    "    \n",
    "    return model, scaler, predictions, scores\n",
    "\n",
    "def student_result_interpretation(df, predictions, scores, feature_names):\n",
    "    \"\"\"\n",
    "    YOUR TASK: Interpret your model's results and provide insights\n",
    "    \n",
    "    Consider:\n",
    "    - What patterns did your model find?\n",
    "    - Which features were most important?\n",
    "    - How would you explain the results to a security team?\n",
    "    \"\"\"\n",
    "    \n",
    "    # STUDENT CODE HERE:\n",
    "    results_df = df.copy()\n",
    "    results_df['breach_risk_prediction'] = predictions  # -1 = high risk, 1 = low risk\n",
    "    results_df['breach_risk_score'] = scores  # Lower = higher risk\n",
    "    results_df['high_breach_risk'] = predictions == -1\n",
    "    \n",
    "    high_risk_users = results_df[results_df['high_breach_risk']]\n",
    "    low_risk_users = results_df[~results_df['high_breach_risk']]\n",
    "    \n",
    "    print(f\"\\nüéØ YOUR MODEL RESULTS:\")\n",
    "    print(f\"‚Ä¢ High breach risk users: {len(high_risk_users)} ({len(high_risk_users)/len(results_df)*100:.1f}%)\")\n",
    "    print(f\"‚Ä¢ Low breach risk users: {len(low_risk_users)}\")\n",
    "    \n",
    "    if len(high_risk_users) > 0:\n",
    "        print(f\"\\nüö® HIGH BREACH RISK USERS:\")\n",
    "        \n",
    "        # Sort by risk score (most negative = highest risk)\n",
    "        sorted_high_risk = high_risk_users.sort_values('breach_risk_score')\n",
    "        \n",
    "        for _, user in sorted_high_risk.head(3).iterrows():\n",
    "            print(f\"\\nüîç {user['user_name']} ({user['access_level']})\")\n",
    "            print(f\"   ‚Ä¢ Risk Score: {user['breach_risk_score']:.3f}\")\n",
    "            \n",
    "            # Feature analysis\n",
    "            if 'risk_ratio' in user.index:\n",
    "                print(f\"   ‚Ä¢ Risk Ratio: {user['risk_ratio']:.3f} (sensitive/total access)\")\n",
    "            if 'escalation_potential' in user.index:\n",
    "                print(f\"   ‚Ä¢ Escalation Potential: {user['escalation_potential']:.1f}\")\n",
    "            \n",
    "            print(f\"   ‚Ä¢ Total Access: {user['total_access_count']}\")\n",
    "            print(f\"   ‚Ä¢ Sensitive Data: {user['sensitive_data_reachable']}\")\n",
    "            \n",
    "            # Student interpretation\n",
    "            print(f\"   ‚Ä¢ YOUR ANALYSIS: [Explain why this user is high risk]\")\n",
    "    \n",
    "    # Feature importance analysis (manual for unsupervised)\n",
    "    print(f\"\\nüìä FEATURE ANALYSIS:\")\n",
    "    for feature in feature_names:\n",
    "        if feature in results_df.columns:\n",
    "            high_risk_avg = high_risk_users[feature].mean() if len(high_risk_users) > 0 else 0\n",
    "            low_risk_avg = low_risk_users[feature].mean() if len(low_risk_users) > 0 else 0\n",
    "            difference = abs(high_risk_avg - low_risk_avg)\n",
    "            \n",
    "            print(f\"‚Ä¢ {feature}:\")\n",
    "            print(f\"  - High risk avg: {high_risk_avg:.2f}\")\n",
    "            print(f\"  - Low risk avg: {low_risk_avg:.2f}\")\n",
    "            print(f\"  - Difference: {difference:.2f}\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Execute the challenge\n",
    "try:\n",
    "    print(\"\\nüöÄ EXECUTING YOUR CUSTOM SECURITY MODEL...\")\n",
    "    \n",
    "    # Step 1: Feature Engineering\n",
    "    enhanced_features = student_feature_engineering(security_ml.security_features)\n",
    "    print(f\"‚úÖ Feature engineering complete: {len(enhanced_features.columns)} features\")\n",
    "    \n",
    "    # Step 2: Prepare data for ML\n",
    "    ml_features = ['total_access_count', 'unique_targets_accessed', 'target_diversity',\n",
    "                   'access_method_diversity', 'sensitive_data_reachable', 'roles_assumed',\n",
    "                   'privilege_level', 'risk_ratio', 'escalation_potential']\n",
    "    \n",
    "    # Filter features that exist\n",
    "    available_features = [f for f in ml_features if f in enhanced_features.columns]\n",
    "    X = enhanced_features[available_features].fillna(0)\n",
    "    \n",
    "    print(f\"‚úÖ Using {len(available_features)} features: {available_features}\")\n",
    "    \n",
    "    # Step 3: Train model\n",
    "    model, scaler, predictions, scores = student_model_selection_and_training(X, available_features)\n",
    "    print(f\"‚úÖ Model training complete\")\n",
    "    \n",
    "    # Step 4: Interpret results\n",
    "    final_results = student_result_interpretation(enhanced_features, predictions, scores, available_features)\n",
    "    print(f\"‚úÖ Analysis complete\")\n",
    "    \n",
    "    # Challenge evaluation\n",
    "    breach_risk_users = final_results[final_results['high_breach_risk']]\n",
    "    \n",
    "    print(f\"\\nüèÜ CHALLENGE EVALUATION:\")\n",
    "    print(f\"‚Ä¢ Model successfully identified {len(breach_risk_users)} high-risk users\")\n",
    "    print(f\"‚Ä¢ Feature engineering added meaningful security metrics\")\n",
    "    print(f\"‚Ä¢ Results provide actionable security intelligence\")\n",
    "    \n",
    "    if len(breach_risk_users) > 0:\n",
    "        print(f\"\\nüìã YOUR SECURITY RECOMMENDATIONS:\")\n",
    "        print(f\"1. Immediately investigate {len(breach_risk_users)} high-risk users\")\n",
    "        print(f\"2. Review access logs for unusual patterns\")\n",
    "        print(f\"3. Consider implementing additional monitoring\")\n",
    "        print(f\"4. Verify business justification for high-risk access patterns\")\n",
    "    \n",
    "    print(f\"\\nüéì CHALLENGE STATUS: COMPLETED SUCCESSFULLY!\")\n",
    "    print(f\"You've demonstrated advanced ML skills for cybersecurity!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Challenge error: {e}\")\n",
    "    print(f\"üí° Debug your code and try again!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Final Knowledge Assessment: ML Security Mastery\n",
    "\n",
    "Test your comprehensive understanding of machine learning for cybersecurity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_security_mastery_assessment():\n",
    "    \"\"\"\n",
    "    Comprehensive assessment of ML security knowledge\n",
    "    \"\"\"\n",
    "    print(\"üß† ML SECURITY MASTERY ASSESSMENT\")\n",
    "    print(\"=\"*45)\n",
    "    print(\"\\nTesting your expertise in machine learning for cybersecurity...\\n\")\n",
    "    \n",
    "    score = 0\n",
    "    total_questions = 7\n",
    "    \n",
    "    # Question 1: Algorithm Selection\n",
    "    print(\"1. For detecting users with unusual behavior patterns, which algorithm\")\n",
    "    print(\"   is most appropriate when you don't have labeled attack data?\")\n",
    "    print(\"   a) Supervised classification (Random Forest)\")\n",
    "    print(\"   b) Unsupervised anomaly detection (Isolation Forest)\")\n",
    "    print(\"   c) Reinforcement learning\")\n",
    "    \n",
    "    answer1 = input(\"Your answer (a/b/c): \").strip().lower()\n",
    "    if answer1 == 'b':\n",
    "        print(\"‚úÖ Correct! Unsupervised methods work without labeled attack data.\")\n",
    "        score += 1\n",
    "    else:\n",
    "        print(\"‚ùå Incorrect. Without attack labels, unsupervised methods are needed.\")\n",
    "    \n",
    "    # Question 2: Feature Engineering\n",
    "    print(\"\\n2. Which feature would be most valuable for detecting privilege escalation?\")\n",
    "    print(\"   a) User's email address\")\n",
    "    print(\"   b) Number of different roles a user can assume\")\n",
    "    print(\"   c) User's department\")\n",
    "    \n",
    "    answer2 = input(\"Your answer (a/b/c): \").strip().lower()\n",
    "    if answer2 == 'b':\n",
    "        print(\"‚úÖ Correct! Role access patterns directly relate to privilege escalation.\")\n",
    "        score += 1\n",
    "    else:\n",
    "        print(\"‚ùå Incorrect. Role access patterns are most relevant for privilege detection.\")\n",
    "    \n",
    "    # Question 3: Local vs Global Anomalies\n",
    "    print(\"\\n3. Local Outlier Factor (LOF) is better than Isolation Forest for:\")\n",
    "    print(\"   a) Finding globally unusual users\")\n",
    "    print(\"   b) Finding users unusual within their role/context\")\n",
    "    print(\"   c) Processing very large datasets quickly\")\n",
    "    \n",
    "    answer3 = input(\"Your answer (a/b/c): \").strip().lower()\n",
    "    if answer3 == 'b':\n",
    "        print(\"‚úÖ Correct! LOF excels at contextual anomaly detection.\")\n",
    "        score += 1\n",
    "    else:\n",
    "        print(\"‚ùå Incorrect. LOF finds local/contextual anomalies, not global ones.\")\n",
    "    \n",
    "    # Question 4: Clustering for Security\n",
    "    print(\"\\n4. In security clustering analysis, outlier points (noise) often represent:\")\n",
    "    print(\"   a) Normal users with typical behavior\")\n",
    "    print(\"   b) Users requiring security investigation\")\n",
    "    print(\"   c) System administrators\")\n",
    "    \n",
    "    answer4 = input(\"Your answer (a/b/c): \").strip().lower()\n",
    "    if answer4 == 'b':\n",
    "        print(\"‚úÖ Correct! Clustering outliers often indicate suspicious behavior.\")\n",
    "        score += 1\n",
    "    else:\n",
    "        print(\"‚ùå Incorrect. Outliers in security clustering are suspicious and need investigation.\")\n",
    "    \n",
    "    # Question 5: Model Interpretation\n",
    "    print(\"\\n5. When explaining ML security results to executives, you should:\")\n",
    "    print(\"   a) Show only the technical algorithm details\")\n",
    "    print(\"   b) Focus on business risk and actionable recommendations\")\n",
    "    print(\"   c) Present raw mathematical scores without context\")\n",
    "    \n",
    "    answer5 = input(\"Your answer (a/b/c): \").strip().lower()\n",
    "    if answer5 == 'b':\n",
    "        print(\"‚úÖ Correct! Business context and actionable insights are key for executives.\")\n",
    "        score += 1\n",
    "    else:\n",
    "        print(\"‚ùå Incorrect. Executives need business-relevant insights, not technical details.\")\n",
    "    \n",
    "    # Question 6: False Positives\n",
    "    print(\"\\n6. High false positive rates in security ML models lead to:\")\n",
    "    print(\"   a) Better security coverage\")\n",
    "    print(\"   b) Alert fatigue and reduced effectiveness\")\n",
    "    print(\"   c) Improved model accuracy\")\n",
    "    \n",
    "    answer6 = input(\"Your answer (a/b/c): \").strip().lower()\n",
    "    if answer6 == 'b':\n",
    "        print(\"‚úÖ Correct! Too many false alarms cause teams to ignore alerts.\")\n",
    "        score += 1\n",
    "    else:\n",
    "        print(\"‚ùå Incorrect. High false positives create alert fatigue and reduce trust.\")\n",
    "    \n",
    "    # Question 7: Continuous Learning\n",
    "    print(\"\\n7. Security ML models should be retrained regularly because:\")\n",
    "    print(\"   a) Attack patterns and normal behavior evolve over time\")\n",
    "    print(\"   b) It's required by compliance regulations\")\n",
    "    print(\"   c) Newer algorithms are always better\")\n",
    "    \n",
    "    answer7 = input(\"Your answer (a/b/c): \").strip().lower()\n",
    "    if answer7 == 'a':\n",
    "        print(\"‚úÖ Correct! Security landscapes constantly evolve, requiring model updates.\")\n",
    "        score += 1\n",
    "    else:\n",
    "        print(\"‚ùå Incorrect. Models need retraining to adapt to evolving threats and behaviors.\")\n",
    "    \n",
    "    # Final assessment\n",
    "    percentage = (score / total_questions) * 100\n",
    "    print(f\"\\nüéØ Final Score: {score}/{total_questions} ({percentage:.0f}%)\")\n",
    "    \n",
    "    if score == total_questions:\n",
    "        print(\"üèÜ EXCEPTIONAL! You've mastered ML for cybersecurity!\")\n",
    "        print(\"üéì Ready to lead security data science initiatives.\")\n",
    "        print(\"üöÄ Consider advanced topics: deep learning, real-time detection, threat intelligence.\")\n",
    "    elif score >= 6:\n",
    "        print(\"üéñÔ∏è EXCELLENT! Strong expertise in security machine learning.\")\n",
    "        print(\"üìà Ready for advanced ML security projects.\")\n",
    "        print(\"üí° Review any missed concepts and explore specialized applications.\")\n",
    "    elif score >= 5:\n",
    "        print(\"üëç GOOD! Solid foundation in ML security concepts.\")\n",
    "        print(\"üìö Practice more with real datasets and advanced algorithms.\")\n",
    "        print(\"üéØ Focus on model interpretation and business communication.\")\n",
    "    elif score >= 3:\n",
    "        print(\"üìñ DEVELOPING. Basic understanding with room for growth.\")\n",
    "        print(\"üîÑ Revisit key concepts: anomaly detection, clustering, feature engineering.\")\n",
    "        print(\"üí™ Practice with hands-on projects and real security data.\")\n",
    "    else:\n",
    "        print(\"üìö BEGINNING. Focus on foundational ML and security concepts.\")\n",
    "        print(\"üéØ Recommend reviewing earlier notebooks and practicing fundamentals.\")\n",
    "        print(\"üí° Consider additional ML coursework before specializing in security.\")\n",
    "    \n",
    "    return score\n",
    "\n",
    "# Run the mastery assessment\n",
    "final_ml_score = ml_security_mastery_assessment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Machine Learning Security Mastery Complete!\n",
    "\n",
    "Congratulations on completing the Machine Learning for Security Anomaly Detection module!\n",
    "\n",
    "### üèÜ Advanced ML Skills Mastered:\n",
    "‚úÖ **Isolation Forest** - Global anomaly detection with clear explanations  \n",
    "‚úÖ **DBSCAN Clustering** - User behavior grouping and outlier identification  \n",
    "‚úÖ **Local Outlier Factor** - Context-aware anomaly detection  \n",
    "‚úÖ **Feature Engineering** - Transforming security data for ML consumption  \n",
    "‚úÖ **Model Interpretation** - Explaining AI decisions to security teams  \n",
    "‚úÖ **Composite Risk Scoring** - Combining multiple ML methods for robust detection  \n",
    "‚úÖ **Security Dashboard Creation** - Operational ML for cybersecurity  \n",
    "\n",
    "### üß† Key Educational Insights:\n",
    "- **Why ML Works for Security:** Patterns in data reveal hidden threats\n",
    "- **Algorithm Selection:** Match the algorithm to the security problem\n",
    "- **Interpretability Matters:** Security teams need to understand AI decisions\n",
    "- **Context is Critical:** Local anomalies often more relevant than global ones\n",
    "- **Continuous Learning:** Security ML requires regular model updates\n",
    "\n",
    "### üéØ Real-World Applications:\n",
    "- **Insider Threat Detection** - Find employees with suspicious access patterns\n",
    "- **Account Compromise Detection** - Identify hijacked user accounts  \n",
    "- **Privilege Abuse Monitoring** - Detect misuse of administrative access\n",
    "- **Behavioral Baseline Establishment** - Define normal user behavior per role\n",
    "- **Risk-Based Authentication** - Dynamic security based on behavior analysis\n",
    "\n",
    "### üöÄ Next Learning Adventures:\n",
    "1. **06-Graph-Algorithms-Security.ipynb** - Graph theory for attack path optimization\n",
    "2. **07-Risk-Scoring-Models.ipynb** - Advanced risk quantification methods\n",
    "3. **08-Threat-Hunting-Automation.ipynb** - Automated detection development\n",
    "\n",
    "### üíº Career Impact:\n",
    "- **Security Data Scientist** - Apply ML to cybersecurity challenges\n",
    "- **Threat Detection Engineer** - Build automated security monitoring\n",
    "- **Security Analyst** - Use ML tools for investigation and analysis\n",
    "- **Security Architect** - Design ML-powered security systems\n",
    "\n",
    "---\n",
    "\n",
    "### ü§ñ Remember: Machine Learning is a Tool, Not Magic\n",
    "\n",
    "**Key Principles for ML Security Success:**\n",
    "- **Start with the security problem**, not the ML algorithm\n",
    "- **Validate results** with security experts and domain knowledge\n",
    "- **Explain decisions** - black box ML creates liability in security\n",
    "- **Monitor and retrain** - security landscapes constantly evolve\n",
    "- **Combine with human expertise** - ML augments, doesn't replace, analysts\n",
    "\n",
    "**üéì Ready to apply graph algorithms to security analysis?**\n",
    "\n",
    "Continue to **06-Graph-Algorithms-Security.ipynb** to learn how graph theory optimizes attack path analysis and defensive strategies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session cleanup and achievement tracking\n",
    "if 'security_ml' in locals():\n",
    "    security_ml.driver.close()\n",
    "    print(\"‚úÖ ML Security Education Session Complete!\")\n",
    "    print(f\"üéØ Final Assessment Score: {final_ml_score}/7\")\n",
    "    print(\"ü§ñ Machine Learning for Security: MASTERED\")\n",
    "    print(\"\\nüöÄ Ready for Advanced Graph Algorithms!\")\n",
    "    print(\"üìä You can now build production ML security systems!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}